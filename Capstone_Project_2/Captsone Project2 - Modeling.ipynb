{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPSTONE PROJECT 2: A COMPUTER VISION MODEL WHICH DETECTS BONE FRACTURES IN THE UPPER EXTREMITIES NAMELY: WRISTS, FOREARMS, UPPER ARM, & SHOULDER FRACTURES\n",
    "#### Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Goal: Build two to three different models and identify the best one. <br>\n",
    "- Fit your models with a training dataset<bf>\n",
    "Hint: Try a number of different models: you will want to compare their outputs in the\n",
    "model evaluation stage. For example, if you’re writing a classification model, you should\n",
    "implement both an entropy model and a Gini impurity model. For hyperparameter tuning,\n",
    "think of methods like cross-validation.<br>\n",
    "- Review model outcomes — Iterate over additional models as needed<br>\n",
    "Hint: you may want to use standard model evaluation metrics such as accuracy, recall,\n",
    "precision, and F1.<br>\n",
    "- Identify the final model that you think is the best model for this project<br>\n",
    "Hint: the most powerful model isn’t always the best one to use. Other considerations\n",
    "include computational complexity, scalability, and maintenance costs.<br>\n",
    "Review the following questions and apply them to your analysis:<br>\n",
    "- Does my data involve a time series or forecasting? If so, am I splitting the train\n",
    "and test data appropriately?<br>\n",
    "- Is my response variable continuous or categorical?<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from random import sample\n",
    "\n",
    "# Image Analysis imports\n",
    "import sklearn as skl\n",
    "import skimage as ski\n",
    "import cv2\n",
    "from skimage.filters import sobel\n",
    "from skimage import exposure\n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage.filters import threshold_yen\n",
    "from skimage import measure\n",
    "from skimage.segmentation import slic\n",
    "\n",
    "# PyTorch Analysis imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import torchvision\n",
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# Feature extraction imports\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN\n",
    "from torchvision.models.detection.backbone_utils import LastLevelMaxPool\n",
    "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data as Pandas DataFrames: df_test, df_train, df_val\n",
    "data_links = [r'C:\\Users\\micha\\OneDrive\\Documents\\GitHub\\SpringBoardDataScience\\Capstone_Project_2\\Data\\df_test.csv', \n",
    "              r'C:\\Users\\micha\\OneDrive\\Documents\\GitHub\\SpringBoardDataScience\\Capstone_Project_2\\Data\\df_train.csv', \n",
    "              r'C:\\Users\\micha\\OneDrive\\Documents\\GitHub\\SpringBoardDataScience\\Capstone_Project_2\\Data\\df_val.csv']\n",
    "\n",
    "def multi_df(list):\n",
    "    temp_list = []\n",
    "    for i in list:\n",
    "        temp_list.append(pd.read_csv(i))\n",
    "    return temp_list\n",
    "    \n",
    "df_test, df_train, df_val = multi_df(data_links)\n",
    "\n",
    "# Trim the extra index column\n",
    "df_train.drop(columns='Unnamed: 0', inplace=True)\n",
    "df_test.drop(columns='Unnamed: 0', inplace=True)\n",
    "df_val.drop(columns='Unnamed: 0', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "# Project Main Directory path\n",
    "dir_path = r\"C:\\Users\\micha\\OneDrive\\Documents\\GitHub\\SpringBoardDataScience\\Capstone_Project_2\"\n",
    "\n",
    "# Data Paths\n",
    "train_dir_path = r\"C:\\Users\\micha\\OneDrive\\Documents\\GitHub\\SpringBoardDataScience\\Capstone_Project_2\\Data\\train\"\n",
    "val_dir_path = r\"C:\\Users\\micha\\OneDrive\\Documents\\GitHub\\SpringBoardDataScience\\Capstone_Project_2\\Data\\valid\"\n",
    "test_dir_path = r\"C:\\Users\\micha\\OneDrive\\Documents\\GitHub\\SpringBoardDataScience\\Capstone_Project_2\\Data\\test\"\n",
    "\n",
    "# Image Scalars\n",
    "Width = 400\n",
    "Height = 400\n",
    "\n",
    "# Labels\n",
    "num_classes = 8\n",
    "classes=['elbow positive', 'fingers positive', 'forearm fracture', 'humerus fracture', 'humerus', 'shoulder fracture', 'wrist positive', 'no fracture']\n",
    "c2l={k:v for k,v in list(zip(classes,list(range(num_classes))))}\n",
    "l2c={v:k for k,v in c2l.items()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
